{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write AlexNet from Scratch\n",
    "**AlexNet** architecture in PyTorch by completing the required sections. The model should include convolutional layers, ReLU activations, pooling layers, and fully connected layers to process image data for classification tasks.\n",
    "\n",
    "1. Define the AlexNet Architecture:\n",
    "**Feature Extractor (Convolutional Base):**\n",
    "* Stack convolutional layers with appropriate kernel sizes, strides, and paddings.\n",
    "* Use nn.ReLU as the activation function after each convolution.\n",
    "* Apply nn.MaxPool2d after selected layers to reduce spatial dimensions.\n",
    "**Classifier (Fully Connected Layers):**\n",
    "* Flatten the output from the convolutional base.\n",
    "* Add fully connected layers with ReLU activations and dropout for regularization.\n",
    "* End with a final linear layer projecting to the number of output classes.\n",
    "  \n",
    "2. Implement the Forward Method:\n",
    "* Pass the input image through the convolutional base.\n",
    "* Flatten the feature map output to a vector.\n",
    "* Pass it through the fully connected classifier to produce final predictions.\n",
    "\n",
    "3. Weight Initialization:\n",
    "* Initialize weights of convolutional and linear layers using a normal distribution.\n",
    "* Set biases to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T14:29:25.282996Z",
     "iopub.status.busy": "2026-02-17T14:29:25.282411Z",
     "iopub.status.idle": "2026-02-17T14:29:25.287027Z",
     "shell.execute_reply": "2026-02-17T14:29:25.286393Z",
     "shell.execute_reply.started": "2026-02-17T14:29:25.282959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T14:39:56.591166Z",
     "iopub.status.busy": "2026-02-17T14:39:56.590356Z",
     "iopub.status.idle": "2026-02-17T14:39:58.152775Z",
     "shell.execute_reply": "2026-02-17T14:39:58.152190Z",
     "shell.execute_reply.started": "2026-02-17T14:39:56.591136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dataset\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(224), #resize to Alexnet input\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5,),(0.5,))\n",
    "    ])\n",
    "\n",
    "train_data=datasets.CIFAR10(root=\"./data\",train=True,download=True,transform=transform)\n",
    "train_loader=DataLoader(train_data,batch_size=128,shuffle=True,num_workers=4,pin_memory=True,persistent_workers=True)\n",
    "\n",
    "test_data=datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)\n",
    "test_loader=DataLoader(test_data,batch_size=128,shuffle=False,num_workers=4,pin_memory=True,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T14:40:00.270810Z",
     "iopub.status.busy": "2026-02-17T14:40:00.270067Z",
     "iopub.status.idle": "2026-02-17T14:40:00.279112Z",
     "shell.execute_reply": "2026-02-17T14:40:00.278407Z",
     "shell.execute_reply.started": "2026-02-17T14:40:00.270776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#defining Alexnet\n",
    "class Alexnet_rk(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(Alexnet_rk,self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(3,96,kernel_size=11,stride=4,padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96,256,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(256,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,num_classes)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self,x):\n",
    "       x=self.features(x)\n",
    "       x = self.avgpool(x)\n",
    "       x=torch.flatten(x,1)\n",
    "       x=self.classifier(x)\n",
    "       return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "       for m in self.modules():\n",
    "           if isinstance(m,nn.Conv2d):\n",
    "               nn.init.normal_(m.weight,mean=0.0,std=0.01)\n",
    "               nn.init.constant_(m.bias,0)\n",
    "           elif isinstance(m,nn.Linear):\n",
    "               nn.init.normal_(m.weight,mean=0.0,std=0.01)\n",
    "               nn.init.constant_(m.bias,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T14:40:02.787720Z",
     "iopub.status.busy": "2026-02-17T14:40:02.787083Z",
     "iopub.status.idle": "2026-02-17T14:40:03.589091Z",
     "shell.execute_reply": "2026-02-17T14:40:03.588494Z",
     "shell.execute_reply.started": "2026-02-17T14:40:02.787691Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=Alexnet_rk(num_classes=10).to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T14:40:08.790523Z",
     "iopub.status.busy": "2026-02-17T14:40:08.790180Z",
     "iopub.status.idle": "2026-02-17T17:56:12.504278Z",
     "shell.execute_reply": "2026-02-17T17:56:12.503127Z",
     "shell.execute_reply.started": "2026-02-17T14:40:08.790499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Loss:705.4093 | Accuracy:33.33%\n",
      "Epoch:1 | Loss:523.8876 | Accuracy:51.39%\n",
      "Epoch:2 | Loss:427.8716 | Accuracy:61.05%\n",
      "Epoch:3 | Loss:365.9384 | Accuracy:67.02%\n",
      "Epoch:4 | Loss:323.7436 | Accuracy:70.74%\n",
      "Epoch:5 | Loss:287.4380 | Accuracy:74.24%\n",
      "Epoch:6 | Loss:255.1913 | Accuracy:77.07%\n",
      "Epoch:7 | Loss:228.1779 | Accuracy:79.58%\n",
      "Epoch:8 | Loss:203.9353 | Accuracy:81.73%\n",
      "Epoch:9 | Loss:181.4172 | Accuracy:83.76%\n",
      "Epoch:10 | Loss:159.5619 | Accuracy:85.69%\n",
      "Epoch:11 | Loss:139.4556 | Accuracy:87.51%\n",
      "Epoch:12 | Loss:123.7486 | Accuracy:88.79%\n",
      "Epoch:13 | Loss:108.3243 | Accuracy:90.29%\n",
      "Epoch:14 | Loss:97.4408 | Accuracy:91.17%\n",
      "Epoch:15 | Loss:80.3561 | Accuracy:92.84%\n",
      "Epoch:16 | Loss:73.6210 | Accuracy:93.36%\n",
      "Epoch:17 | Loss:64.1876 | Accuracy:94.22%\n",
      "Epoch:18 | Loss:57.8729 | Accuracy:94.82%\n",
      "Epoch:19 | Loss:53.3413 | Accuracy:95.29%\n",
      "Epoch:20 | Loss:48.5626 | Accuracy:95.67%\n",
      "Epoch:21 | Loss:44.3105 | Accuracy:96.13%\n",
      "Epoch:22 | Loss:39.9445 | Accuracy:96.41%\n",
      "Epoch:23 | Loss:38.7980 | Accuracy:96.54%\n",
      "Epoch:24 | Loss:35.8351 | Accuracy:96.86%\n",
      "Epoch:25 | Loss:32.3269 | Accuracy:97.27%\n",
      "Epoch:26 | Loss:31.8447 | Accuracy:97.23%\n",
      "Epoch:27 | Loss:29.7227 | Accuracy:97.37%\n",
      "Epoch:28 | Loss:29.4219 | Accuracy:97.40%\n",
      "Epoch:29 | Loss:26.9013 | Accuracy:97.60%\n",
      "Epoch:30 | Loss:27.3044 | Accuracy:97.66%\n",
      "Epoch:31 | Loss:25.4323 | Accuracy:97.80%\n",
      "Epoch:32 | Loss:24.8132 | Accuracy:97.76%\n",
      "Epoch:33 | Loss:22.4689 | Accuracy:98.04%\n",
      "Epoch:34 | Loss:22.4750 | Accuracy:98.02%\n",
      "Epoch:35 | Loss:23.4114 | Accuracy:98.09%\n",
      "Epoch:36 | Loss:20.6000 | Accuracy:98.31%\n",
      "Epoch:37 | Loss:22.0694 | Accuracy:98.07%\n",
      "Epoch:38 | Loss:22.5462 | Accuracy:98.11%\n",
      "Epoch:39 | Loss:17.9985 | Accuracy:98.44%\n",
      "Epoch:40 | Loss:18.9295 | Accuracy:98.34%\n",
      "Epoch:41 | Loss:17.3409 | Accuracy:98.58%\n",
      "Epoch:42 | Loss:17.5397 | Accuracy:98.55%\n",
      "Epoch:43 | Loss:17.1641 | Accuracy:98.53%\n",
      "Epoch:44 | Loss:17.3788 | Accuracy:98.48%\n",
      "Epoch:45 | Loss:16.6702 | Accuracy:98.58%\n",
      "Epoch:46 | Loss:16.2854 | Accuracy:98.60%\n",
      "Epoch:47 | Loss:14.9176 | Accuracy:98.74%\n",
      "Epoch:48 | Loss:15.2683 | Accuracy:98.65%\n",
      "Epoch:49 | Loss:15.1009 | Accuracy:98.70%\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    correct=0\n",
    "    total=0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs,labels=imgs.to(device),labels.to(device)\n",
    "        output = model(imgs)\n",
    "        loss=criterion(output,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "        _,predicted=output.max(1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=predicted.eq(labels).sum().item()\n",
    "    print(f\"Epoch:{epoch} | Loss:{running_loss:.4f} | Accuracy:{100*correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T18:08:44.178456Z",
     "iopub.status.busy": "2026-02-17T18:08:44.178070Z",
     "iopub.status.idle": "2026-02-17T18:08:55.465997Z",
     "shell.execute_reply": "2026-02-17T18:08:55.465261Z",
     "shell.execute_reply.started": "2026-02-17T18:08:44.178432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.03%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        output = model(imgs)\n",
    "        predicted = output.argmax(dim=1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
